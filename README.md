[Under development]

#gpt
In this repo a decoder transformer was implemented following the classic paper [Attention is all you need](https://arxiv.org/abs/1706.03762) and inspired by Andrej Karpathy's [video](https://www.youtube.com/watch?v=kCc8FmEb1nY).

#tokenizer
Moreover, a simple tokenizer was implemented using byte-pair encoding. This is not yet finished but it will used to improve the current model.